{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Context-Adaptive Distributions for Neural-Based Lossless Image Compression","text":"<p>Authors: Victor Fabre Figueiredo (Student Member, IEEE), Lucas S. Lopes (Member, IEEE), Ricardo L. de Queiroz (Fellow, IEEE), Philip A. Chou (Fellow, IEEE)</p> <p>Abstract</p> <p>We present an innovative method for lossless coding using prediction and context-adaptive Laplacian modeling to code the residuals. Given a causal context, one lightweight neural network predicts the signal mean, while another estimates the scale of the prediction residual, assuming a zero-mean Laplacian density for the residual. The density is integrated to estimate a probability of the quantized residual, which drives an adaptive arithmetic coder to code the quantized residual. We show that with suitable quantization of the residual, this method is equivalent to using a shifted Laplacian to drive an arithmetic coder to code the original quantized signal. The networks are jointly trained to minimize the resulting bit rate. We instantiate different architectures to evaluate the method on 4K frames from the Ultra Video Group (UVG) dataset, and compare to High Efficiency Video Coding (HEVC) Intra Lossless, Free Lossless Image Format (FLIF), Context-Adaptive Lossless Image Compression (CALIC), and Context-based Bit-plane Codec (CBPNNv). Results show that the best architecture variant (a multi-layer perceptron) outperforms the competition, reducing the average bit rate by 30.58% relative to HEVC Intra Lossless and outperforming the state-of-the-art, CBPNNv, on average, while remaining shallow enough for real-time operation. These results indicate that jointly predicting the mean of the signal and scale of the prediction residuals enables efficient lossless coding.</p>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li>\ud83d\udcca Results table: Results</li> <li>\ud83d\udcc4 Paper PDF: add link here </li> <li> <p>\ud83e\uddea Dataset (UVG 4K frames): https://ultravideo.fi/dataset.html A. Mercat, M. Viitanen, and J. Vanne, \u201cUVG dataset: 50/120fps 4K sequences for video codec analysis and development,\u201d in Proc. ACM Multimedia Syst. Conf., Istanbul, Turkey, June 2020.</p> </li> <li> <p>Evaluation: UVG 4K; competitors: HEVC Intra Lossless, FLIF, CALIC, CBPNNv.</p> </li> </ul> BibTeX (placeholder \u2014 substitua quando o DOI estiver dispon\u00edvel) <pre><code>@misc{fabre2025contextadaptive,\n  title   = {Context-Adaptive Distributions for Neural-Based Lossless Image Compression},\n  author  = {Victor Fabre Figueiredo and Lucas S. Lopes and Ricardo L. de Queiroz and Philip A. Chou},\n  year    = {2025},\n  note    = {Supplementary material},\n  howpublished = {\\url{https://&lt;usuario&gt;.github.io/paper-supplement}}\n}\n</code></pre>"},{"location":"#acknowledgments-optional","title":"Acknowledgments (optional)","text":"<p>Add funding, grants, or institutional acknowledgments here.</p>"},{"location":"results/","title":"Context-Adaptive Distributions for Neural-Based Lossless Image Compression","text":"<p>Authors: Victor Fabre Figueiredo (Student Member, IEEE), Lucas S. Lopes (Member, IEEE), Ricardo L. de Queiroz (Fellow, IEEE), Philip A. Chou (Fellow, IEEE)</p> <p>Abstract</p> <p>We present an innovative method for lossless coding using prediction and context-adaptive Laplacian modeling to code the residuals. Given a causal context, one lightweight neural network predicts the signal mean, while another estimates the scale of the prediction residual, assuming a zero-mean Laplacian density for the residual. The density is integrated to estimate a probability of the quantized residual, which drives an adaptive arithmetic coder to code the quantized residual. We show that with suitable quantization of the residual, this method is equivalent to using a shifted Laplacian to drive an arithmetic coder to code the original quantized signal. The networks are jointly trained to minimize the resulting bit rate. We instantiate different architectures to evaluate the method on 4K frames from the Ultra Video Group (UVG) dataset, and compare to High Efficiency Video Coding (HEVC) Intra Lossless, Free Lossless Image Format (FLIF), Context-Adaptive Lossless Image Compression (CALIC), and Context-based Bit-plane Codec (CBPNNv). Results show that the best architecture variant (a multi-layer perceptron) outperforms the competition, reducing the average bit rate by 30.58% relative to HEVC Intra Lossless and outperforming the state-of-the-art, CBPNNv, on average, while remaining shallow enough for real-time operation. These results indicate that jointly predicting the mean of the signal and scale of the prediction residuals enables efficient lossless coding.</p>"},{"location":"results/#bit-rate-results","title":"Bit-rate Results","text":"<p>Bit-rate savings (in %) are reported relative to HEVC Intra Lossless. Values are in bpp; parentheses show savings vs HEVC.</p> Bit-rate results. Bit-rate savings (in %) against HEVC Intra Lossless also indicated. Video Sequence State-of-the-art codecs Proposed method HEVC Intra Lossless FLIF CALIC CBPNNv CNN MLP Transformer Beauty 3.76 3.45 (8.14%) 3.42 (8.91%) 3.40 (9.61%) 2.22 (41.06%) 2.08 (44.56%) 3.39 (9.81%) Bosphorus 3.12 2.48 (20.65%) 2.43 (22.15%) 2.38 (23.73%) 2.90 (7.08%) 2.37 (23.91%) 2.92 (6.45%) HoneyBee 3.57 3.01 (15.62%) 2.97 (16.69%) 2.94 (17.44%) 2.70 (24.25%) 2.59 (27.48%) 2.94 (17.63%) Jockey 3.18 2.76 (13.10%) 2.75 (13.39%) 2.71 (14.80%) 2.51 (20.87%) 2.38 (25.15%) 2.73 (13.94%) ReadySteadyGo 3.47 2.75 (20.70%) 2.68 (22.72%) 2.62 (24.62%) 2.85 (17.77%) 2.33 (32.82%) 2.63 (24.24%) ShakeNDry 4.16 3.23 (22.31%) 3.15 (24.28%) 3.15 (24.25%) 2.67 (35.80%) 2.65 (36.22%) 3.07 (26.19%) YachtRide 3.41 2.65 (22.19%) 2.56 (24.89%) 2.51 (26.53%) 3.14 (7.99%) 2.59 (23.94%) 3.18 (6.88%) Average bpp 3.52 2.90 (17.53%) 2.85 (19.00%) 2.81 (20.14%) 2.71 (22.12%) 2.43 (30.58%) 2.98 (15.02%)"},{"location":"results/#notes","title":"Notes","text":"<ul> <li>Dataset: UVG (4K frames).  </li> <li>Competitors: HEVC Intra Lossless, FLIF, CALIC, CBPNNv.  </li> <li>Proposed variants: CNN, MLP (best), Transformer.</li> </ul>"}]}